第3章：版本
版本查看：
1.  DNNDK中的“host_x86”文件夹包含了主机端的工具DECENT 和 DNNC
	decent --version
	dnnc --version
    DNNDK包含的组件：DExplore、DSigh、DPU driver、 runtime N2Cube.运行命令查看版本
	dexplorer -v

升级与移植：
1.  N2Cube runtime APIs增加了新的中断处理模式，可以在不退出运行的情况下打印log信息。使用dpuGetExceptionMessage()
打印log信息。为了兼容之前版本，默认是不处理error并推出运行的，可以使用 dpuSetExceptionMode()使用新的模式。
2. 增加了4个API函数到 libn2cube中：
	dpuRunSoftmax()
	dpuSetExceptionMode()
	dpuGetExceptionMode()
	dpuGetExceptionMessage()


第4章：DNNDK
1.  DNNDK为DPU(Deeplearning Processor Unit)提供了全栈的深度学习SDK。它为深度神经网络推断应用提供了裁剪、量化、
编译、优化、运行时支持。有如下的特点：
	* 提供全套的工具链，包括压缩、编译、运行时
	* 轻量级C/C++ 编程APIs
	* 易于使用与循序渐进的学习曲线
DNNDK使没有FPGA知识的开发者，使用轻量级C/C++ APIs开发深度学习推断应用变得简单。摒弃了底层FPGA的复杂。

2.  DPU
    DPU用来加速计算深度学习推断算法计算，广泛用于向图像/视频分类、语义分割、物体检测和跟踪等计算机视觉应用。
高效张量级指令集被用于支持流行的卷积神经网络，像VGG、ResNet、GoogLeNet、YOLO、SSD、MobileNet等。DPU可以
被裁减，适用于多款Xilinx Zynq/MPSoC 器件。从边缘到云端，满足多种应用需求。
    DPU包含：
	DECENT(Deep Compression Tool )、
	DNNC(Deep Neural Network Compiler)、
	DNNAS(Deep Neural Network Assembler)、
	N2Cube(Neural Network Runtime)、
	DPU Simulator、
	DPU Profiler、

**  DECENT
    推理过程计算量大，需要较高的内存带宽来满足边缘应用程序的低延迟和高吞吐量要求。DECENTTM (Deep Compression Tool)
，采用粗粒度的修剪、经过训练的量化和权重共享来解决这些问题，同时以非常小的精度降低实现高性能和高能效。

**  DNNC
    DNNC?(深层神经网络编译器)是DPU专用编译器设计。它将神经网络算法映射到DPU指令，通过平衡计算工作负载和内存访问
来实现DPU资源的最大利用率。

** N2Cube
    N2Cube(中立网络的多维数据集)是DPU运行时引擎。它充当DNNDK应用程序的加载程序，处理资源分配和DPU调度。
其核心组件包括DPU驱动程序、DPU加载程序、跟踪程序和应用程序开发的编程api。
    N2Cube 通过一个库提供了一组轻量级编程接口，该库抽象出底层硬件实现的细节。
    DPU Driver 在Linux操作系统的内核空间中运行，包括任务调度和高效的内存管理等DPU功能，以避免DPU和CPU之间的
内存复制开销。
    DPU Loader 负责将DPU代码和数据动态加载到DPU专用内存空间，并执行运行时地址重定位。
    DPU Profiler 使程序员能够分析DPU代码的效率和资源的利用率。

**  DNNAS
    DNNAS (Deep Neural Network Assembler)负责将DPU指令汇编成ELF格式的二进制代码。它属于DNNC代码生成后端组件
，不能单独调用。

**  Profiler
    DPU Profiler 由两部分组成:DPU Tracer和DSight。DPU Tracer是在DNNDK runtime N2cube中实现的，它负责在DPU上
运行神经网络时收集原始剖析数据。使用提供的原始分析数据，DSight可以帮助生成用于性能分析的可视化图表。
    
