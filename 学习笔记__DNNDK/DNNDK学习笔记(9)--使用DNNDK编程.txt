第7章 
1.  编程模型
    理解DNNDK的编程模型后，将更容易的在DPU平台上开发和部署深度学习网络。相应的概念包括：
 “DPU Kernel、DPU Task、DPU Node、DPU Tensor. 其中前两个是DNNDK编程的核心概念。
	
2.  DPU Kernel：
	    通过DNNC编译后，将神经网络model转换为等效DPU汇编文件，他会被DNNAS汇编为可执行文件。
	DPU elf可执行文件被称为”DPU kernel“。
	    在调用 dupLoadKernel（）后，从runtime N2Cube角度看，DPU kernel将变成一个可执行unit。
	N2Cube将会装载DPU kernel（包括DPU指令和网络参数）到特定的内存空间并分配硬件资源。
	然后，通过调用 dpuCreateTask()来启用多线程编程，可以将每个DPU内核实例化为几个DPU任务。

3.  DPU Task：
	    每个DPU Task是DPU kernel的一个运行实体。Task有自己的“私有内存空间”，所以多线程应用可用于同时
	处理多个tasks，来提高效率和吞吐量。

4. DPU Node：
	    DPU Node，被认为是部署在DPU上的网络模型的基本元素。每个DPU节点都与输入、输出和一些参数相关联。
	每个DPU节点都有唯一的名称，允许DNNDK导出的exported api访问它的信息。
	有3种节点类型：
	*  边界输入节点：在DPU kernel拓扑中，它没有任何precursor的节点；通常是第一个node，有时一个kernel
		          有多个边界输入节点。
	*  边界输出节点：在DPU kernel中，它后面没有后继的节点。
	*  其他不适input 和 output boundary node 的节点，都可以叫internal nodes。
    编译之后，DNNC将会给出关于kernel的信息和kernel 的边界输入输出节点信息。下面是编译Iception-v1的示例:
“conv1_7x7_s2”是DPU kernel 0的边界输入节点，“inception_5b_output” 是DPU kernel 0的边界输出节点。
    使用dpuGetInputTensor* / dpuSetInputTensor*时，需要参数“nodeName”来指定边界输入节点。如果参数
”nodeName“不是一个有效的边界输入节点，DNNDK会给出报错信息。
    同样的，使用dpuGetOutputTensor* / dpuSetOutputTensor*时，参数如果不是正确的边界输出节点，也会报错。

5.  DPU Tensor：
    DPU Tensor是一组多维数据集，用于存储运行信息。Tensor的属性信息(长、宽、通道...)可以通过DNNDK的APIs获取。


6.  编程接口
    DNNDK提供了一组封装在几个库中的轻量级C/ C++ api，以平滑DPU的深度学习程序开发。详见12章。在进行DPU
开发时，经常会进行CPU与GPU的数据交互。如，例如，CPU预处理的数据可以发送到DPU进行加速，DPU的输出可能
需要复制回CPU进一步处理。DNNDK提供了一组APIs，使这些工作变得简单。一些示例：
	APIs to set input tensor for a computation layer or node: 为层or节点设置输入数据：
	- dpuSetInputTensor()
	- dpuSetInputTensorInCHWInt8()
	- dpuSetInputTensorInCHWFP32()
	- dpuSetInputTensorInHWCInt8()
	- dpuSetInputTensorInHWCFP32()

	APIs to get output tensor from a n a computation layer or node: 获取计算or节点的输出：
	- dpuGetOutputTensor()
	- dpuGetOutputTensorInCHWInt8()
	- dpuGetOutputTensorInCHWFP32()
	- dpuGetOutputTensorInHWCInt8()
	- dpuGetOutputTensorInHWCFP32()

